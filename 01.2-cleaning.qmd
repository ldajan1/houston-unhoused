---
title: "Cleaning"
format: html
---

## Goals for this notebook
1. Evaluate data cleanliness
2. Group by dates
3. Add amount fined column
4. Select columns
5. Remove repeated rows
6. Check for data date gaps
7. Export clean data

## Setup

Loading the libraries.

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(janitor)
library(stringr)
```

## Importing

```{r}
unhoused_geocoded <- read_csv("data-processed/unhoused_geocodio_combined.csv")
```

## 1.Evaluating data cleanliness

```{r}
unhoused_geocoded |> glimpse()
```

## 1.1. Cleaning names

```{r}
unhoused_clean_names <- unhoused_geocoded |> 
  clean_names()

unhoused_clean_names |> glimpse()
```

## 1.2. Fixing dates

```{r}
unhoused_dates <- unhoused_clean_names |> #@ i see at least one test row
  mutate(offense_date = as_date(offense_date),
         judgment_date = as_date(judgment_date)
         )

unhoused_dates |> glimpse()
```

## 1.3 Merging misspelled columns

### 1.3.1 Evaluating columns

Looking at columns to evaluate which function to use.

```{r}
unhoused_dates |> 
  select(defendant_address, defendent_address)
```

### 1.3.2 Merging

Merging defendant_address and defendent_address into one column.

```{r}
unhoused_coalesce <- unhoused_dates |>
  mutate(
    defendant_address = coalesce(defendant_address, defendent_address) # this function is able to generate a complete vector from partially missing pieces
  ) |> 
  select(!defendent_address)

unhoused_coalesce |> glimpse()
```

## 2. Grouping by dates

```{r}
unhoused_grouped_dates <- unhoused_coalesce |> 
  mutate(
    off_yr = year(offense_date), # offense year
    off_mo = month(offense_date), # offense month in numbers
    off_mo_label = month(offense_date, label = TRUE), # offense month written
    off_yday = yday(offense_date), # offense day/365
    jud_yr = year(judgment_date),
    jud_mo = month(judgment_date),
    jud_mo_label = month(judgment_date, label = TRUE),
    jud_yday = yday(judgment_date)
  ) 
  
unhoused_dates |> glimpse()
```

## 3. Adding amount fined column

```{r}
unhoused_fined <- unhoused_grouped_dates |>
  mutate(amount_fined = total_fine_amount_due +
                          total_fine_amount_paid +
                          total_fine_amount_dismissed)

unhoused_fined |> glimpse()
```

## 4. Selecting columns

```{r}
unhoused_selected <- unhoused_fined |> 
  select(citation_number,
         case_number,
         offense_date,
         defendant_name,
         defendant_address,
         violation_code,
         violation_description,
         amount_fined,
         fines_due = total_fine_amount_due,
         fines_paid = total_fine_amount_paid,
         fines_dismissed = total_fine_amount_dismissed,
         judgment_date,
         judgment,
         disposition,
         data_origin,
         full_address,
         geocodio_latitude,
         geocodio_longitude,
         geocodio_accuracy_score,
         geocodio_accuracy_type,
         geocodio_address_line_1,
         geocodio_address_line_2,
         geocodio_address_line_3,
         geocodio_house_number,
         geocodio_street,
         geocodio_unit_type,
         geocodio_unit_number,
         geocodio_city,
         geocodio_state,
         geocodio_county,
         geocodio_postal_code,
         geocodio_country,
         geocodio_source
         )

unhoused_selected |> glimpse()
```

## 5. @Duplicate rows

### 1.1 Finding dupes

```{r}
unhoused_selected |> 
   get_dupes(!data_origin)
```

### 1.2 No dupes

Getting rid of those duplicates.

```{r}
# unhoused_clean <- unhoused_selected |> 
#   distinct(across(!data_origin), .keep_all = TRUE) # this is originally how i had it to keep the data_origin column, but not consider it when looking for distinct rows
# 
# unhoused_clean |> glimpse()
```

```{r}
unhoused_clean <- unhoused_selected |> 
  select(!data_origin) |> 
  distinct()

unhoused_clean |> glimpse()
```

### 1.3 Problem

Finding duplicate case numbers.

```{r}
unhoused_dupes |> 
  get_dupes(case_number) |> #@ not all of these are problematic, some just have different judgment dates and that makes sense. but many only differ by defendant_address, and sometimes it's only a difference of a comma

  arrange(offense_date)
```

Highlighting a specific case I think is problematic.

```{r}
unhoused_clean |> 
  filter(case_number == "N35532892-01 NT 2025") #@ of these three case_number dupes, the last row has a different judgment_date and judgment, but the first two rows are the same aside from the comma in defendant_address.
```

Proposed solution:

```{r}
unhoused_test <- unhoused_selected |>
  distinct(across(!c(
    data_origin,
    defendant_address)), 
    .keep_all = TRUE) #@ i think ignoring defendant_address in distinct() along with data_origin should take care of the issue. maybe i can get rid of defendant_address overall since we've already geocoded?

unhoused_test |> glimpse()
```

Now looking at that same example case.

```{r}
unhoused_test |> 
  filter(case_number == "N35532892-01 NT 2025")
```

## 6. Checking for data gaps

### 6.1 Making a date ranges object

Preparing the data

```{r}
unhoused_date_range <- unhoused_clean |> 
  select(offense_date) |> 
  arrange(offense_date)

unhoused_date_range |> glimpse()
```

### 6.2 Plotting

```{r}
ggplot(unhoused_date_range, 
       aes(x = offense_date, y = 1)) +
  geom_point() +
  labs(
    title = "All Citations by Offense Date",
    x = "Offense Date",
    y = ""
  ) +
  theme_minimal()
```

## 7. Exporting

```{r}
unhoused_clean |> 
  write_csv("data-processed/unhoused-clean.csv")
```
