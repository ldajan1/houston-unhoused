---
title: "Geocoding"
format: html
---

## Goals of this notebook

1. Merge data sets
2. Geocode addresses
3. Export

## Setup

Loading the libraries.

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(janitor)
library(readxl)
library(sf)
library(tidygeocoder)
```

## Importing

Data set 1.

```{r}
unhoused_raw_1 <- suppressWarnings(read_excel("data-raw/unhoused-raw-1.xlsx"))
```

Data Set 2.

```{r}
unhoused_raw_2 <- suppressWarnings(read_excel("data-raw/unhoused-raw-2.xlsx"))
```

## 1. Merging data sets

### 1.1 Evaluating merge readiness

Ensuring column names match.

```{r}
unhoused_raw_1 |> glimpse()
unhoused_raw_2 |> glimpse()
```

### 1.3 Cleaning names

#### 1.3.1 Data set 1

```{r}
unhoused_names_1 <- unhoused_raw_1 |> 
  clean_names()

unhoused_names_1 |> glimpse()
```

#### 1.3.2 Data set 2

```{r}
unhoused_names_2 <- unhoused_raw_2 |> 
  clean_names()

unhoused_names_2 |> glimpse()
```

### 1.4 Preparing to merge

#### 1.4.1 Data set 1

Fixing phone_number data type for data set 1, fixing misspellings and adding data origin column to data set 1.

```{r}
unhoused_tidy_1 <- unhoused_names_1 |>
  mutate(phone_number = as.character(phone_number),
         data_origin = "unhoused_1"
         ) |> 
  rename(total_fine_amount_due = totla_fine_amount_due,
         total_fine_amount_paid = totla_fine_amount_paid,
         total_fine_amount_dismissed = totla_fine_amount_dismissed)

unhoused_tidy_1 |> glimpse()
```

#### 1.4.2 Data set 2

Adding data origin column to data set 2 and renaming columns to match data set 1.

```{r}
unhoused_tidy_2 <- unhoused_names_2 |> 
  mutate(data_origin = "unhoused_2") |> 
  select(citation_number,
         case_number,
         offense_date,
         defendant_name,
         defendant_address,
         phone_number = defendant_phone_number,
         offense_location,
         violation_code,
         violation_description,
         total_fine_amount_due,
         total_fine_amount_paid,
         total_fine_amount_dismissed,
         judgment_date,
         judgment,
         disposition,
         data_origin
         )

unhoused_tidy_2 |> glimpse()
```

### 1.5 Merging sheets

Merging sheets and removing repeated rows.

```{r}
unhoused_merged <- bind_rows(unhoused_tidy_1, unhoused_tidy_2)

unhoused_merged |> glimpse()
```

## 2. Removing repeated rows

Finding out which rows are repeats.

```{r}
unhoused_merged |> 
  count(case_number) |> 
  filter(n > 1)
```

The above rows are the rows where the two data sets merged, as seen at the end of unhoused-raw-1.xlsx. Getting rid of repeat rows:

```{r}
unhoused_repeat <- unhoused_merged |> 
  arrange(desc(offense_date)) |> 
  group_by(case_number) |> 
  slice(1)

unhoused_repeat |> glimpse()
```

Making sure it worked.

```{r}
unhoused_repeat |> 
  count(case_number) |> 
  filter(n > 1)
```

## 3. Geocoding addresses

### 3.1 Reformatting addresses

```{r}
unhoused_geo_prep <- unhoused_repeat |>
  mutate(full_address = paste(offense_location, "Houston, TX", sep = ", "))

unhoused_geo_prep |> glimpse()
```

### 3.2 Geocoding

```{r}
unhoused_geocoded <- geocode(
  unhoused_geo_prep,
  address = full_address,
  method = "osm",
  lat = latitude,
  long = longitude
)

unhoused_geocoded |> glimpse()
```

## 4. Exporting

```{r}
unhoused_geocoded |>
  write_rds("data-processed/unhoused-geocoded.rds")
```










<!-- ## Making district zones -->

<!-- We are looking at offense location, not defendant address. -->

<!-- ### Grouping locations -->

<!-- Seeing if there are enough repeated offense locations to manually bucket them into zones -->

<!-- ```{r} -->
<!-- unhoused_dates |>  -->
<!--   count(offense_location) |> -->
<!--   arrange(desc(n)) -->
<!-- ``` -->

<!-- ### Splitting -->

<!-- Splitting the street name and number so I can sort by each individually. -->

<!-- ```{r} -->
<!-- unhoused_split <- unhoused_dates |> -->
<!--   mutate( -->
<!--     address_parts = str_split(offense_location, ",", simplify = TRUE), # this splits address at comma, and simplify turns thw results into matrix -->
<!--     street_number = str_trim(address_parts[, 1]), # this pulls info before the comma -- number in this case -->
<!--     street_name = ifelse(address_parts[, 2] == "", NA_character_, str_trim(address_parts[, 2])) #this means if the number of address parts is >=2, (another part to the address), gets rid of excess spaces, and saves the result as a street_name. NA character is just telling R what to do if there's no comma -->
<!--   ) |> -->
<!--   select(-address_parts) -->

<!-- unhoused_split |> glimpse() -->
<!-- ``` -->

<!-- ### Checking number of street names -->

<!-- ```{r} -->
<!-- unhoused_split |> -->
<!--   count(street_name) |> -->
<!--   arrange(desc(n)) -->
<!-- ``` -->


<!-- ### Forming the zones -->

<!-- ```{r} -->
<!-- # unhoused_zoned <- unhoused_split |> -->
<!-- #   mutate( -->
<!-- #     zone = case_when( -->
<!-- #       street == "FANNIN" & address_number >= 100 & address_number <= 500 ~ "Central Business District") -->
<!-- #       ) -->
<!-- ``` -->










